{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install snntorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import torch, torch.nn as nn\n",
    "import snntorch as snn\n",
    "import snntorch.functional as SF\n",
    "\n",
    "from torch import randn_like\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "data_path='C:/desktop' # Directory where MNIST dataset is stored\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # Use GPU if available\n",
    "\n",
    "# Define a transform to normalize data\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((28, 28)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "# Download and load the training and test FashionMNIST datasets\n",
    "# fmnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transform)\n",
    "fmnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_epochs\": 100,  # Number of epochs to train for (per trial)\n",
    "    \"batch_size\": 128,  # Batch size\n",
    "    \"seed\": 0,  # Random seed\n",
    "\n",
    "\n",
    "    # Network parameters\n",
    "    \"batch_norm\": True,  # Whether or not to use batch normalization\n",
    "    \"dropout\": 0.13,  # Dropout rate\n",
    "    \"beta\": 0.39,  # Decay rate parameter (beta)\n",
    "    \"threshold\": 1.5,  # Threshold parameter (theta)\n",
    "    \"lr\": 2.0e-3,  # Initial learning rate\n",
    "    \"slope\": 7.7,  # Slope value (k)\n",
    "\n",
    "    # Fixed params\n",
    "    \"num_steps\": 100,  # Number of timesteps to encode input for\n",
    "    \"correct_rate\": 0.8,  # Correct rate\n",
    "    \"incorrect_rate\": 0.2,  # Incorrect rate\n",
    "    \"betas\": (0.9, 0.999),  # Adam optimizer beta values\n",
    "    \"eta_min\": 0,  # Minimum learning rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config['batch_size']\n",
    "# trainloader = DataLoader(fmnist_train, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(fmnist_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import surrogate\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.thr = config[\"threshold\"]\n",
    "        self.slope = config[\"slope\"]\n",
    "        self.beta = config[\"beta\"]\n",
    "        self.num_steps = config[\"num_steps\"]\n",
    "        self.batch_norm = config[\"batch_norm\"]\n",
    "        self.p1 = config[\"dropout\"]\n",
    "        self.spike_grad = surrogate.fast_sigmoid(self.slope)\n",
    "\n",
    "        # Initialize Layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5, bias=False)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        self.lif1 = snn.Leaky(self.beta, threshold=self.thr, spike_grad=self.spike_grad)\n",
    "        self.conv2 = nn.Conv2d(16, 64, 5, bias=False)\n",
    "        self.conv2_bn = nn.BatchNorm2d(64)\n",
    "        self.lif2 = snn.Leaky(self.beta, threshold=self.thr, spike_grad=self.spike_grad)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 10, bias=False)\n",
    "        self.lif3 = snn.Leaky(self.beta, threshold=self.thr, spike_grad=self.spike_grad)\n",
    "        self.dropout = nn.Dropout(self.p1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk3_rec = []\n",
    "        mem3_rec = []\n",
    "\n",
    "        # Forward pass\n",
    "        for step in range(self.num_steps):\n",
    "            cur1 = F.avg_pool2d(self.conv1(x), 2)\n",
    "            if self.batch_norm:\n",
    "                cur1 = self.conv1_bn(cur1)\n",
    "\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = F.avg_pool2d(self.conv2(spk1), 2)\n",
    "            if self.batch_norm:\n",
    "                cur2 = self.conv2_bn(cur2)\n",
    "\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.dropout(self.fc1(spk2.flatten(1)))\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "            spk3_rec.append(spk3)\n",
    "            mem3_rec.append(mem3)\n",
    "\n",
    "        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n",
    "\n",
    "net = Net(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config, net, testloader, device=device):\n",
    "    \"\"\"Calculate accuracy on full test set.\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs, _ = net(images)\n",
    "            accuracy = SF.accuracy_rate(outputs, labels)\n",
    "            total += labels.size(0)\n",
    "            correct += accuracy * labels.size(0)\n",
    "\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(),\n",
    "    lr=config[\"lr\"], betas=config[\"betas\"]\n",
    ")\n",
    "criterion = SF.mse_count_loss(correct_rate=config[\"correct_rate\"],\n",
    "    incorrect_rate=config[\"incorrect_rate\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install aihwkit first\n",
    "# !pip install aihwkit\n",
    "# !conda install -c conda-forge aihwkit-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import aihwkit libraries here\n",
    "from aihwkit.simulator.configs import (\n",
    "    InferenceRPUConfig,\n",
    ")\n",
    "from aihwkit.inference import PCMLikeNoiseModel, ReRamWan2022NoiseModel, GlobalDriftCompensation\n",
    "\n",
    "rpu_config = InferenceRPUConfig()\n",
    "rpu_config.noise_model = PCMLikeNoiseModel(g_max=25.0)  # PCM noise model\n",
    "# rpu_config.noise_model = ReRamWan2022NoiseModel(g_max=40.0) # RRAM noise model\n",
    "\n",
    "rpu_config.mapping.max_input_size = 256\n",
    "rpu_config.mapping.max_output_size = 256\n",
    "\n",
    "rpu_config.forward.out_noise = 0.04\n",
    "rpu_config.forward.inp_res = 2**8\n",
    "rpu_config.forward.out_res = 2**8\n",
    "# rpu_config.drift_compensation = GlobalDriftCompensation() #Enable only for PCM devices\n",
    "\n",
    "from aihwkit.nn.conversion import convert_to_analog\n",
    "# from aihwkit.simulator.presets import StandardHWATrainingPreset\n",
    "from aihwkit.inference.calibration import (\n",
    "    calibrate_input_ranges,\n",
    "    InputRangeCalibrationType,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_inferences = [0.0, 3600.0, 86400.0]  # Times to perform inference on PCM.\n",
    "# t_inferences = [1.0, 86400.0, 172800.0] # Times to perform inference on RRAM.\n",
    "n_reps = 5  # Number of inference repetitions.\n",
    "\n",
    "model = Net(config)\n",
    "model.load_state_dict(torch.load(r'fmnist_fp32.pt', map_location=torch.device('cpu'))) # load the trained model here\n",
    "model.to(device)\n",
    "model.eval()\n",
    "accuracy = test(config, model, testloader, device)\n",
    "print(f\"Original accuracy: {accuracy}\")\n",
    "model = convert_to_analog(model, rpu_config=rpu_config)\n",
    "model.eval() # Determine the inference accuracy with the specified rpu configuration.\n",
    "print(f\"Evaluating imported model number.\")\n",
    "inference_accuracy_values = torch.zeros((len(t_inferences), n_reps))\n",
    "for t_id, t in enumerate(t_inferences):\n",
    "  for i in range(n_reps):\n",
    "    model.drift_analog_weights(t)\n",
    "    accuracy = test(config, model, testloader, device)\n",
    "    inference_accuracy_values[t_id, i] = accuracy\n",
    "    print(\n",
    "        f\"Test set accuracy (%) at t={t}s: mean: {inference_accuracy_values[t_id].mean()}, \\\n",
    "        std: {inference_accuracy_values[t_id].std()}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
